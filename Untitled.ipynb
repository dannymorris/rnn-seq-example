{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78634921-aeba-4514-9c69-6d7151fa5185",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be6a8a19-fd2a-415f-bebb-3123a52b4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras\n",
    "#pip install keras.utils\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c7429e6-826d-4c2a-92cf-8383b033c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576e659-d1d2-41e2-91d8-7fa65971683d",
   "metadata": {},
   "source": [
    "# Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dbf0fed-2311-413e-a767-69263ed269ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqFile = 'sequences.pkl'\n",
    "labelFile = 'labels.pkl'\n",
    "timeFile = 'times.pkl'\n",
    "\n",
    "sequences = np.array(pickle.load(open(seqFile, 'rb')), dtype='object')\n",
    "labels = np.array(pickle.load(open(labelFile, 'rb')), dtype='float32')\n",
    "times = np.array(pickle.load(open(timeFile, 'rb'), encoding='latin1'), dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "64f060b8-c5f0-4e8a-9f64-bd99bf3a69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.concatenate([np.ones(50), np.zeros(50)])\n",
    "x2 = np.concatenate([np.zeros(50), np.ones(50)])\n",
    "xs = np.array(list(zip(x1, x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76d0abdb-a26c-4d32-ad2c-49a811a7a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7847/322132478.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  np.random.random_integers(0, 1, len(seq_idx))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_integers(0, 1, len(seq_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603838fa-5aae-4074-8ec8-2a9f517af53d",
   "metadata": {},
   "source": [
    "# Convert raw data to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4caf064b-bc73-480d-addc-05a2c62fb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_idx = np.arange(len(sequences))\n",
    "seq_idx = np.concatenate([list(itertools.repeat(x, len(y))) for x,y in zip(seq_idx, sequences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8109d326-205f-45a6-b0fb-1578d91c0566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  values  times\n",
       "0   0      79     50\n",
       "1   0      44     57\n",
       "2   0      89     77\n",
       "3   0      24    124\n",
       "4   0      36    199"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'id': seq_idx, \n",
    "    'values': np.concatenate(sequences), \n",
    "    'times': np.concatenate(times)\n",
    "    }\n",
    "\n",
    "d = pd.DataFrame(d)\n",
    "\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbabc3-f983-46c7-aa9b-d52e4b0efc9e",
   "metadata": {},
   "source": [
    "# Extract sequences and time duration feature from DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c046c0-e4f7-45cd-871f-b1523c355956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(d.groupby(['id'], sort=False).values.apply(list).tolist(), dtype=object)\n",
    "times = np.array(d.groupby(['id'], sort=False).times.apply(list).tolist(), dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e800b-180d-4cb7-bb36-faf767f39677",
   "metadata": {},
   "source": [
    "# Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3092562-668a-41c9-9bc8-08fb81778eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 79, 44,\n",
       "       89, 24, 36, 14, 10, 10,  5, 59, 66, 91, 62, 11, 60, 54, 22, 61, 41,\n",
       "       51, 52, 21, 12,  1,  7, 33, 30, 79, 78, 40, 48, 98, 56, 39, 85,  8,\n",
       "       84, 51, 23, 13, 22, 26, 37, 66, 47, 21, 72, 67, 16,  3, 22, 87, 88,\n",
       "        6, 56, 85,  8,  8, 76,  7, 47, 23, 14, 84, 95, 22, 78, 46, 48, 16,\n",
       "       22, 34], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_padded = sequence.pad_sequences(sequences)\n",
    "seqs_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e250c40-7b3e-4467-b4c8-ea4c24960964",
   "metadata": {},
   "source": [
    "# Pad time duration feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aad664d9-d0a7-4f39-b84d-1c070cc04fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   50,\n",
       "         57,   77,  124,  199,  209,  262,  361,  457,  473,  561,  633,\n",
       "        642,  651,  663,  759,  840,  925,  955,  958, 1019, 1069, 1137,\n",
       "       1148, 1208, 1255, 1292, 1309, 1407, 1445, 1495, 1593, 1681, 1779,\n",
       "       1818, 1823, 1920, 1995, 2078, 2114, 2159, 2178, 2241, 2286, 2348,\n",
       "       2436, 2479, 2491, 2514, 2525, 2579, 2656, 2726, 2814, 2903, 2964,\n",
       "       3061, 3089, 3103, 3175, 3245, 3248, 3305, 3315, 3318, 3347, 3396,\n",
       "       3493, 3585, 3666, 3747, 3790], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_padded = sequence.pad_sequences(times)\n",
    "times_padded = np.array(times_padded)\n",
    "times_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab42df-2ed0-40ad-8137-694a13bff805",
   "metadata": {},
   "source": [
    "# One-hot encode sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fcefc3f-bf7b-416a-899f-5e4566edb06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_encoded = to_categorical(seqs_padded)\n",
    "seqs_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d1d977-2d76-4482-925a-4fa2d53e8f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 104, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_encoded.shape\n",
    "# n sequences = 100   len(sequences)\n",
    "# max length = 104    np.max([np.max(i) for i in sequences])\n",
    "# unique ints = 100   len(np.unique(np.concatenate(sequences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8573b3-12ca-431a-8971-379d0e0d712c",
   "metadata": {},
   "source": [
    "# Append time duration feature to encoded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43552cb2-50eb-4890-9437-d7c1188a3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_time(ohe, time):\n",
    "    out = [np.append(i, j) for i,j in zip(ohe, time)]\n",
    "    return(out)\n",
    "\n",
    "seqs_with_time = np.array([append_time(seqs_encoded[i], times_padded[i]) for i in range(len(seqs_encoded))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "274f982e-1046-4065-9508-22a1a243e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   1.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   1.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [   0.,    0.,    0., ...,    0., 3666., 3666.],\n",
       "       [   0.,    0.,    0., ...,    0., 3747., 3747.],\n",
       "       [   0.,    0.,    0., ...,    0., 3790., 3790.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_with_time[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70843df-5387-433a-be18-3d527673909b",
   "metadata": {},
   "source": [
    "# Create LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cebc30b-3236-4dc3-b05f-4d4168a7d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, timesteps, features = seqs_with_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04ba3993-e288-4906-86a1-a814380b3508",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Concatenate' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model2\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m merged \u001b[38;5;241m=\u001b[39m Concatenate([model, model2])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmerged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m merged\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m merged\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Concatenate' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value = 0., input_shape=(timesteps, features)))\n",
    "model.add(LSTM(100, return_sequences=True, dropout=0.2))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "merged = Concatenate([model, model2])\n",
    "\n",
    "merged.add(Dense(1, activation='sigmoid'))\n",
    "merged.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "merged.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf1fe9-ccf4-45b1-8836-5848edda3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_out = (static_input)\n",
    "\n",
    "x = LSTM(n_cell_lstm, return_sequences=True)(dynamic_input)\n",
    "x = Flatten()(x)\n",
    "dynamic_out = (x)\n",
    "\n",
    "z = concatenate([dynamic_out, static_out])\n",
    "\n",
    "z = Dense(64, activation='relu')(z)\n",
    "\n",
    "main_output = Dense(classes, activation='softmax', name='main_output')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "daac936b-3a68-424f-90da-79de82b7ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "static_out = (xs)\n",
    "\n",
    "visible = Input(shape=(timesteps, features))\n",
    "hidden1 = LSTM(10, return_sequences=True)(visible)\n",
    "hidden1 = Flatten()(hidden1)\n",
    "\n",
    "z = concatenate([hidden1, xs])\n",
    "\n",
    "z = Dense(64, activation='relu')(z)\n",
    "\n",
    "main_output = Dense(1, activation='softmax', name='main_output')(z)\n",
    "\n",
    "model = Model(inputs=[visible], outputs=main_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ecb166b-6775-474b-a5a5-8dc884620a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 104, 102)]        0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 104, 10)           4520      \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1040)              0         \n",
      "                                                                 \n",
      " concatenate_5 (Concatenate)  (100, 1042)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (100, 64)                 66752     \n",
      "                                                                 \n",
      " main_output (Dense)         (100, 1)                  65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,337\n",
      "Trainable params: 71,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "de037e80-33a2-4165-bf12-1802a430a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "38ade604-eceb-44e1-bc88-9435e6b3af46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/concatenate_5/concat' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7847/182558895.py\", line 1, in <cell line: 1>\n      model.fit(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/merge.py\", line 183, in call\n      return self._merge_function(inputs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/merge.py\", line 531, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 3313, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/concatenate_5/concat'\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [1,1040] vs. shape[1] = [100,2]\n\t [[{{node model/concatenate_5/concat}}]] [Op:__inference_train_function_42348]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [153]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseqs_with_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/concatenate_5/concat' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7847/182558895.py\", line 1, in <cell line: 1>\n      model.fit(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/merge.py\", line 183, in call\n      return self._merge_function(inputs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/merge.py\", line 531, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 3313, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/concatenate_5/concat'\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [1,1040] vs. shape[1] = [100,2]\n\t [[{{node model/concatenate_5/concat}}]] [Op:__inference_train_function_42348]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "\tx=seqs_with_time, y=labels,\n",
    "\tepochs=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b4fd8-fb9f-4ad0-ae48-91a54b68bb73",
   "metadata": {},
   "source": [
    "# Fit, evaluate, and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e328a5c-9447-4e33-8168-41eaa7562493",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs_with_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:3059\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3054\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3055\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3056\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3057\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3060\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3061\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(seqs_with_time, labels, epochs=3, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a70517d4-a39e-4cfc-9f7c-1a1df9037585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2918994426727295, 0.9200000166893005]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(seqs_with_time, labels, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6cfb2c3-7dc4-4fe1-87b9-f6e791664d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05783281],\n",
       "       [0.05624515],\n",
       "       [0.06183383],\n",
       "       [0.05807522],\n",
       "       [0.05601501]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(seqs_with_time)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb23ef-a55b-4d23-9265-7bb6f0e83f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1680/1687370789.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  seqs = np.array(d.groupby(['id'], sort=False).values.apply(list).tolist())\n",
      "/tmp/ipykernel_1680/1687370789.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ts = np.array(d.groupby(['id'], sort=False).times.apply(list).tolist())\n"
     ]
    }
   ],
   "source": [
    "seqs = np.array(d.groupby(['id'], sort=False).values.apply(list).tolist())\n",
    "ts = np.array(d.groupby(['id'], sort=False).times.apply(list).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
